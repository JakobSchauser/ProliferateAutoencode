import math
import os
from typing import Tuple

import numpy as np

import torch
import torch.nn as nn
from torch_geometric.nn import NNConv


class ParticleNCA_edge(nn.Module):
	"""
	Off-grid (particle-based) Neural Cellular Automata in PyTorch.

	Each particle (cell) has features:
	  - x, y: position
	  - heading: 2D orientation vector (len <= 1)
	  - molecules: hidden channels of size `molecule_dim`

	Neighborhood: k-NN with cutoff radius. Messages are computed using
	relative features (dx, dy, heading delta features, neighbor molecules - self molecules).

	The model predicts deltas for updates:
	  (dx, dy, d_angle, d_molecules)

	Notes:
	- Heading is required and used for body-frame projections and directional gating.

	Usage:
	  nca = ParticleNCA(molecule_dim=16, k=16, cutoff=0.25)
	  x = torch.randn(N, 2)             # positions
	  mol = torch.randn(N, 16)          # molecules
	  gen = torch.zeros(N, 1)           # generation number (int-like float)
	  heading = torch.randn(N, 2)
	  heading = heading / (heading.norm(dim=-1, keepdim=True) + 1e-12)
	  dx, dtheta, dmol, divide_logit = nca(x, mol, gen, globals, heading)
	"""

	def __init__(
		self,
		molecule_dim: int,
		n_globals: int,
		k: int = 16,
		cutoff: float = 0.25,
		message_hidden: int = 64,
		update_hidden: int = 64,
		heads: int = 2,
	):
		super().__init__()
		self.molecule_dim = molecule_dim
		self.n_globals = n_globals
		self.k = k
		self.cutoff = cutoff
		self.heads = heads

		# Message MLP takes relative inputs
		# Inputs per edge:
		# - dx, dy, r, forward, lateral (body-frame projections)
		# - chirality: molecule-gated signed lateral component (local handedness)
		# - sin(d_angle), cos(d_angle)
		# - (mol_j - mol_i) molecules difference
		rel_geom_dim = 6  # dx, dy, r, fwd, lat, chirality

		angle_dim = 2
		rel_input_dim = rel_geom_dim + angle_dim + 2 * molecule_dim + 2 * n_globals

		self.message_mlp = nn.Sequential(
			nn.Linear(rel_input_dim, message_hidden),
			nn.ReLU(inplace=True),
			nn.Linear(message_hidden, message_hidden),
			nn.ReLU(inplace=True),
			nn.Linear(message_hidden, message_hidden),
			nn.ReLU(inplace=True),
		)

		# Node feature dimensionality (used as node input to attention conv)
		# Components: heading(x,y), molecules, generation, degree (n-connections), globals
		self.self_feat_dim = 2 + molecule_dim + 1 + 1 + n_globals
		# Edge attributes passed into attention conv: encoded edge + self (dst) features
		edge_attr_dim = message_hidden + self.self_feat_dim
		# Edge-conditioned message passing: per-edge weights generated by MLP on edge_attr
		self.edge_nn = nn.Sequential(
			nn.Linear(edge_attr_dim, message_hidden),
			nn.ReLU(inplace=True),
			nn.Linear(message_hidden, message_hidden),
			nn.ReLU(inplace=True),
			nn.Linear(message_hidden, self.self_feat_dim * update_hidden),
		)
		self.nn_conv = NNConv(
			in_channels=self.self_feat_dim,
			out_channels=update_hidden,
			nn=self.edge_nn,
			aggr='mean',
		)
		# Node head maps attended features to deltas
		self.node_head = nn.Sequential(
			nn.Linear(update_hidden, update_hidden),
			nn.ReLU(inplace=True),
			nn.Linear(update_hidden, update_hidden),
			nn.ReLU(inplace=True),
			nn.Linear(update_hidden, 2 + 1 + molecule_dim + 2),  # dx, dy, d_angle, d_molecules, divide_vec(x,y)
		)

	@staticmethod
	def _pairwise_dist(x: torch.Tensor) -> torch.Tensor:
		# x: (N, 2)
		# returns (N, N) pairwise euclidean distances
		# Using cdist might be memory hungry; manual is fine for moderate N.
		# dist_ij = ||x_i - x_j||
		xi = x.unsqueeze(1)  # (N,1,2)
		xj = x.unsqueeze(0)  # (1,N,2)
		d = xi - xj
		return torch.sqrt(torch.clamp((d ** 2).sum(-1), min=1e-12))

	def _hard_cutoff_neighbors(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
		"""Symmetrized directed edges using distance cutoff."""
		with torch.no_grad():
			dist = self._pairwise_dist(x)
			N = dist.shape[0]
			dist = dist + torch.eye(N, device=x.device) * 1e6
			mask = dist <= self.cutoff
			# take only upper triangle to form undirected pairs, then duplicate to directed
			tri_mask = torch.triu(mask, diagonal=1)
			dst_u, src_u = torch.where(tri_mask)
			# duplicate to both directions
			src = torch.cat([src_u, dst_u], dim=0)
			dst = torch.cat([dst_u, src_u], dim=0)
		return src, dst
	
	def forward(
		self,
		x: torch.Tensor,           # (N, 2)
		molecules: torch.Tensor,   # (N, molecule_dim)
		generation: torch.Tensor,  # (N, 1) integer-like counter
		globals : torch.Tensor,    # (N, globals)
		heading: torch.Tensor,     # (N,2) heading; required
	) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
		N = x.shape[0]

		src, dst = self._hard_cutoff_neighbors(x)  # (E,), (E,) where E = number of edges
		edge_index = torch.stack([src, dst], dim=0)  # (2, E)

		# Build global edge list - already in the right format from _hard_cutoff_neighbors
		# src: neighbor indices j (E,)
		# dst: target indices i (E,)

		# Gather features per edge
		x_i = x[dst]        # (E,2)
		x_j = x[src]        # (E,2)
		# Use provided heading (can be non-unit; assumed len <= 1)
		heading_full = heading
		h_i = heading_full[dst]  # (E,2)
		h_j = heading_full[src]  # (E,2)
		mol_i = molecules[dst]  # (E,C)
		mol_j = molecules[src]  # (E,C)
		globals_i = globals[dst]  # (E, G)
		globals_j = globals[src]  # (E, G)

		# Relative features per edge
		dxdy = x_j - x_i                # (E,2)
		r = torch.sqrt(torch.clamp((dxdy ** 2).sum(-1, keepdim=True), min=1e-7))  # (E,1)
		# Normalize headings for angular features and body-frame
		h_norm_i = h_i.norm(dim=-1, keepdim=True)
		h_norm_j = h_j.norm(dim=-1, keepdim=True)
		h_hat_i = h_i / (h_norm_i + 1e-12)
		h_hat_j = h_j / (h_norm_j + 1e-12)
		# Vector equivalents of angle delta features
		cos_d = (h_hat_i * h_hat_j).sum(dim=-1, keepdim=True)  # (E,1)
		sin_d = h_hat_i[:, 0:1] * h_hat_j[:, 1:2] - h_hat_i[:, 1:2] * h_hat_j[:, 0:1]  # (E,1)
		ang_feat = torch.cat([sin_d, cos_d], dim=-1)  # (E,2)
		d_mol = mol_j - mol_i           # (E,C)

		debug = bool(os.environ.get("DEBUG_NANS"))
		if debug:
			fin = torch.isfinite(r)
			if not fin.all():
				bad = (~fin).sum().item()
				print(f"[NaN] r non-finite: count={bad}, shape={tuple(r.shape)}")

		# Body-frame projections relative to the destination node's angle
		u_i = h_hat_i  # (E,2)
		v_i = torch.stack([-u_i[:, 1], u_i[:, 0]], dim=-1)  # (E,2) perpendicular to heading
		fwd = (dxdy * u_i).sum(dim=-1, keepdim=True)  # (E,1)
		lat = (dxdy * v_i).sum(dim=-1, keepdim=True)  # (E,1)

		# Local chirality: gate signed lateral by a destination molecule channel (e.g., first)
		chi = torch.tanh(mol_i[:, :1].contiguous())  # (E,1)
		chirality = chi * lat  # (E,1)
		rel_geom = torch.cat([dxdy, r, fwd, lat, chirality], dim=-1)  # (E,6)

		# Per-edge input to message MLP
		rel_in = torch.cat([rel_geom, ang_feat, mol_j, mol_i, globals_j, globals_i], dim=-1)  # (E + molecule_dim + angle_dim + rel_geom_dim)
		if debug:
			if not torch.isfinite(rel_in).all():
				nf = (~torch.isfinite(rel_in)).sum().item()
				print(f"[NaN] rel_in non-finite: count={nf}, shape={tuple(rel_in.shape)}")
		# Guard against any NaNs sneaking in from upstream
		rel_in = torch.nan_to_num(rel_in)

		msg = self.message_mlp(rel_in)  # (E,H)
		if debug and not torch.isfinite(msg).all():
			nf = (~torch.isfinite(msg)).sum().item()
			print(f"[NaN] msg non-finite: count={nf}, shape={tuple(msg.shape)}")
		msg = torch.nan_to_num(msg)

		# Heading-based directional weighting (magnitude modulates strength)
		dxdy_hat = dxdy / (r + 1e-12)  # (E,2)
		m_mag = torch.clamp(h_norm_i, min=0.0, max=1.0)  # assume len <= 1; bound defensively
		dir_weight = (dxdy_hat * h_hat_i).sum(dim=-1, keepdim=True)  # [-1,1]
		gate = 0.5 * (m_mag * dir_weight + 1.0)  # [0,1]
		if debug:
			if not torch.isfinite(gate).all():
				print("[NaN] gate non-finite")
		msg = gate * msg

		# Self features for update head
		# Use provided heading for self features
		self_heading = heading
		# Degree encodes the number of neighbors (n-connections) for each node
		degree = torch.bincount(dst, minlength=N).float().unsqueeze(-1)
		self_feat = torch.cat([self_heading, molecules, generation, degree, globals], dim=-1)  # (N, 2 + C + 1 + 1 + G)
		if debug and not torch.isfinite(self_feat).all():
			print("[NaN] self_feat non-finite")
		self_feat = torch.nan_to_num(self_feat)

		# Edge attributes include encoded edge plus destination self features
		edge_attr = torch.cat([msg, self_feat[dst]], dim=-1)
		if debug and not torch.isfinite(edge_attr).all():
			print("[NaN] edge_attr non-finite")
		edge_attr = torch.nan_to_num(edge_attr)

		# Edge-conditioned aggregation of edge-informed messages
		node_msg = self.nn_conv(self_feat, edge_index, edge_attr)  # (N, update_hidden)
		if debug and not torch.isfinite(node_msg).all():
			print("[NaN] node_msg non-finite")
		node_msg = torch.nan_to_num(node_msg)
		upd = self.node_head(node_msg)  # (N, 2 + 1 + C + 2)
		if debug and not torch.isfinite(upd).all():
			print("[NaN] upd non-finite")

		dxdy = upd[:, 0:2]
		dtheta = upd[:, 2:3]
		dmol = upd[:, 3:3 + self.molecule_dim]
		divide_vec = upd[:, 3 + self.molecule_dim: 5 + self.molecule_dim]



		return dxdy, dtheta, dmol, divide_vec


def _quick_test():
	torch.manual_seed(0)
	N = 128
	C = 16
	x = torch.rand(N, 2)
	mol = torch.randn(N, C)
	nca = ParticleNCA_edge(molecule_dim=C, n_globals=0, k=16, cutoff=0.2)
	gen = torch.zeros(N, 1)
	globals = torch.zeros(N, 0)
	heading = torch.randn(N, 2)
	heading = heading / (heading.norm(dim=-1, keepdim=True) + 1e-12)
	dxdy, dtheta, dmol, div_vec = nca(x, mol, gen, globals, heading)
	assert dxdy.shape == (N, 2)
	assert dtheta.shape == (N, 1)
	assert dmol.shape == (N, C)
	assert div_vec.shape == (N, 2)
	print("ParticleNCA forward OK:", dxdy.mean().item(), dtheta.mean().item(), dmol.mean().item(), div_vec.mean().item())


if __name__ == "__main__":
	_quick_test()

